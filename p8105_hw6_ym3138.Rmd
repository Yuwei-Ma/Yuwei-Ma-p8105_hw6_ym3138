---
title: "HW6"
author: "Yuwei Ma"
output: github_document
header-includes:
      - \usepackage{amsmath}
      - \usepackage{amsfonts}
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r echo = TRUE, message = FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(broom)
library(knitr)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

# Data cleaning and manipulation

```{r}
raw_df = read_csv("data/homicide-data.csv")

homicide_df = 
  raw_df |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved = as.numeric(disposition == "Closed by arrest"), # Strict definition
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")
  ) |> 
  # Omit cities with data issues
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) |> 
  # Limit to White or Black victim race
  filter(victim_race %in% c("White", "Black")) |> 
  select(city_state, resolved, victim_age, victim_race, victim_sex)
```

```{r}
# Filter for Baltimore specifically
baltimore_df = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD")

# Fit the logistic regression model
fit_logistic = 
  baltimore_df |> 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = _, family = binomial()) 

# Tidy the output and calculate Odds Ratios
fit_logistic |> 
  broom::tidy() |> 
  mutate(OR = exp(estimate)) |>
  select(term, log_OR = estimate, OR, p.value) |> 
  knitr::kable(digits = 3, caption = "Baltimore Logistic Regression Results")

# Add predictions (as per your snippet)
baltimore_df |> 
  modelr::add_predictions(fit_logistic) |> 
  mutate(fitted_prob = boot::inv.logit(pred)) |> 
  head() |> 
  knitr::kable(digits = 3, caption = "First 6 rows with fitted probabilities")
```


```{r}
cities_glm = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolved ~ victim_age + victim_race + victim_sex, data = df, family = binomial())),
    results = map(models, broom::tidy)
  ) |> 
  select(-data, -models) |> 
  unnest(results)

# Filter for the term of interest (Male victim) and calculate ORs
cities_OR = 
  cities_glm |> 
  filter(term == "victim_sexMale") |> 
  mutate(
    OR = exp(estimate),
    OR_low = exp(estimate - 1.96 * std.error),
    OR_high = exp(estimate + 1.96 * std.error)
  ) |> 
  select(city_state, OR, OR_low, OR_high)

# Display top 5 cities by Odds Ratio
cities_OR |> 
  arrange(desc(OR)) |> 
  head(5) |> 
  knitr::kable(digits = 3, caption = "Top 5 Cities by Odds Ratio (Male vs Female)")
```



```{r}
cities_OR |> 
  ungroup() |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_low, ymax = OR_high)) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  coord_flip() +
  labs(
    title = "Odds Ratio for Solving Homicides: Male vs Female Victims",
    subtitle = "Definition: Solved = 'Closed by arrest' only",
    x = "City",
    y = "Adjusted Odds Ratio (Male / Female)"
  ) +
  theme_minimal()
```

The plot illustrates a widespread disparity in homicide resolution across major U.S. cities. For nearly all cities, the estimated Odds Ratio (OR) is less than 1.0, indicating that homicides with male victims are significantly less likely to be "closed by arrest" than those with female victims, even after adjusting for victim age and race. Cities like New York and Long Beach show particularly strong disparities, with the odds of resolution for males often half that of females.

Albuquerque, NM, stands out as a notable exception with an OR above 1, suggesting male cases there were more likely to be solved, though the wide confidence intervals imply uncertainty. Overall, the data reveals a systemic trend where victim sex remains a powerful predictor of case clearance, with female victim cases consistently showing higher arrest rates nationwide.

## Problem 2
```{r}
library(p8105.datasets)
library(modelr)
data("weather_df")

set.seed(1)

```


```{r}

weather_central_park = 
  weather_df |>  
  filter(name == "CentralPark_NY") |>  
  select(tmax, tmin, prcp) |>  
  drop_na()

```

# Bootstrapping
```{r}
# Generate 5000 bootstrap samples
boot_straps = 
  weather_central_park |>  
  modelr::bootstrap(n = 5000)

# Fit models and extract results
bootstrap_results = 
  boot_straps |>  
  mutate(
    # Fit the linear model to each bootstrap sample
    models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    
    # Extract R-squared using broom::glance
    glance_results = map(models, broom::glance),
    
    # Extract coefficients using broom::tidy
    tidy_results = map(models, broom::tidy)
  ) 

# Clean up the results for analysis
final_results = 
  bootstrap_results |>  
  select(.id, glance_results, tidy_results) |>  
  unnest(glance_results) |>  
  select(.id, r.squared, tidy_results) |>  
  unnest(tidy_results) |>  
  select(.id, r.squared, term, estimate) |>  
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) |>  
  mutate(
    beta_ratio = tmin / prcp # Calculating beta1 / beta2
  ) |>  
  select(.id, r.squared, beta_ratio)

```

# Dist for r squared
```{r}
final_results |>  
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(
    title = "Distribution of Estimated R-squared",
    x = "Estimated R-squared",
    y = "Density"
  ) +
  theme_minimal()

```

The distribution of \(\hat{r}^2\) appears to be approximately normal, though it may exhibit a slight left skew (tail extending towards lower values). The values are generally high, indicating that tmin and prcp are strong predictors of tmax.


# Dist for beta1/beta2
```{r}
final_results |>  
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(
    title = "Distribution of Estimated Beta Ratio (tmin / prcp) (Zoomed in)",
    x = "Estimate Beta1 / Beta2",
    y = "Density"
  ) +
  coord_cartesian(xlim = c(-50000, 50000)) + 
  theme_minimal() 
```

The distribution is unimodal and roughly symmetric, centered around approximately -25. This indicates that for the majority of bootstrap samples, the coefficient for minimum temperature ($\hat{\beta}_1$) is positive and the coefficient for precipitation ($\hat{\beta}_2$) is small and negative. 

```{r}
final_results |>  
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(
    title = "Distribution of Estimated Beta Ratio (tmin / prcp)",
    x = "Estimate Beta1 / Beta2",
    y = "Density"
  ) +
  theme_minimal() 
```
Here's the distribution without zooming in. The heavy tails are due to bootstrap samples where the precipitation coefficient is extremely close to zero, causing the ratio to take on extreme values.

# Confidence Interval
```{r}
ci_results = 
  final_results |>  
  summarize(
    r_squared_lower = quantile(r.squared, 0.025),
    r_squared_upper = quantile(r.squared, 0.975),
    beta_ratio_lower = quantile(beta_ratio, 0.025, na.rm = TRUE),
    beta_ratio_upper = quantile(beta_ratio, 0.975, na.rm = TRUE)
  )

knitr::kable(ci_results, digits = 3, caption = "95% Confidence Intervals")

```



## Problem 3

```{r}
library(modelr)
library(purrr)
```


```{r}
birthweight_data <- read_csv("data/birthweight.csv")

# Clean data: convert appropriate integers to factors
birthweight_clean <- birthweight_data |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  )

# Check for missing data
sum(is.na(birthweight_clean))
```

# Proposed model: Maternal and Pregnancy factors

A model is proposed based on developmental and maternal factors. Key predictors include gestational age (gaweeks), mother's physical characteristics (ppbmi, mheight), and health behaviors (smoken).

```{r}
model_proposed <- lm(bwt ~ gaweeks + smoken + mheight + ppbmi + wtgain + parity, data = birthweight_clean)

# Add predictions and residuals
birthweight_clean <- birthweight_clean |> 
  add_predictions(model_proposed, var = "pred_proposed") |> 
  add_residuals(model_proposed, var = "resid_proposed")

# Plot residuals vs fitted values
ggplot(birthweight_clean, aes(pred_proposed, resid_proposed)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values (Proposed Model)",
    x = "Fitted Birthweight (grams)",
    y = "Residuals"
  ) +
  theme_minimal()
```

The plot of residuals against fitted values for this proposed model shows a random scatter around zero, suggesting that the linear assumption is largely appropriate, although there is some variance.

# Model comparison via Cross-Validation
```{r}

set.seed(123)

# Create cross-validation folds (Monte Carlo, 100 splits)
cv_df <- crossv_mc(birthweight_clean, n = 100)

# Define the models and compute RMSE
cv_results <- cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    
    # Fit models
    mod_proposed = map(train, ~lm(bwt ~ gaweeks + smoken + mheight + ppbmi + wtgain + parity, data = .)),
    mod_main     = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
    mod_interact = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .)),
    
    # Calculate RMSE on test sets
    rmse_proposed = map2_dbl(mod_proposed, test, rmse),
    rmse_main     = map2_dbl(mod_main, test, rmse),
    rmse_interact = map2_dbl(mod_interact, test, rmse)
  )

# Reshape for plotting
cv_long <- cv_results |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  )

# Visualize RMSE comparison
ggplot(cv_long, aes(x = reorder(model, rmse), y = rmse, fill = model)) +
  geom_boxplot() +
  labs(
    title = "Model Comparison: Cross-Validated Prediction Error",
    x = "Model",
    y = "RMSE (grams)"
  ) +
  theme_minimal()

# Summary Statistics
cv_long |> 
  group_by(model) |> 
  summarize(mean_rmse = mean(rmse)) |> 
  knitr::kable()
```

Using Monte Carlo cross-validation (100 splits, 80/20 train/test), the Root Mean Square Error (RMSE) was calculated for three models to assess prediction accuracy.



  * Model 1 (Including the three-way interaction: Head Circ. $\times$ Length $\times$ Sex Interactions): RMSE $\approx$ 291 grams
  * Model 2 (Main effects only: Length + Gestational Age): RMSE $\approx$ 335 grams
  * Proposed Model (Maternal Factors): RMSE $\approx$ 442 grams
 
Conclusion: Model 1 significantly outperforms the others. This is expected as head circumference and body length are direct physical dimensions of the baby at birth and are mathematically correlated with volume and mass (weight). The proposed model relies on maternal characteristics, which explain less variance than direct measurements of the infant.

