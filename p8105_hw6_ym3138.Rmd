---
title: "HW6"
author: "Yuwei Ma"
output: github_document
header-includes:
      - \usepackage{amsmath}
      - \usepackage{amsfonts}
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r echo = TRUE, message = FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(broom)
library(knitr)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

# Data cleaning and manipulation
```{r}
raw_data <- read_csv("data/homicide-data.csv")
homicide_df <- raw_data |> 
  mutate(city_state = str_c(city, state, sep = ", ")) |> 
  # Create binary resolved variable (1 = Solved, 0 = Unsolved)
  # Assuming "Closed by arrest" and "Closed without arrest" are solved
  mutate(resolved = as.numeric(disposition %in% c("Closed by arrest", "Closed without arrest"))) |> 
  # Omit specific cities
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) |> 
  # Limit to White or Black victim race
  filter(victim_race %in% c("White", "Black")) |> 
  # Ensure victim_age is numeric
  mutate(victim_age = as.numeric(victim_age)) |> 
  # Filter out rows where age became NA (if any non-numeric values existed)
  filter(!is.na(victim_age))
```

# Baltimore Analysis

```{r}
# Filter for Baltimore
baltimore_df <- homicide_df |> 
  filter(city_state == "Baltimore, MD")

# Fit logistic regression
baltimore_glm <- glm(resolved ~ victim_age + victim_sex + victim_race, 
                     data = baltimore_df, 
                     family = binomial())

# Obtain tidy output with ORs and CIs
baltimore_results <- baltimore_glm |> 
  broom::tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  select(term, estimate, conf.low, conf.high)

# Display results
baltimore_results |> 
  knitr::kable(digits = 3, caption = "Adjusted Odds Ratio for Male vs Female Victims in Baltimore")
```

For Baltimore, the adjusted odds ratio for solving homicides comparing male victims to female victims is `r round(baltimore_results$estimate, 3)` (95% CI: `r round(baltimore_results$conf.low, 3)` - `r round(baltimore_results$conf.high, 3)`). This indicates that homicides with male victims are significantly less likely to be solved than those with female victims, holding age and race constant.

# All city analysis
```{r}
# Run glm for each city and extract OR for male sex
city_results <- homicide_df |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    # Fit model for each city
    model = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, 
                           data = ., 
                           family = binomial())),
    # Tidy the model output to get estimates and CIs
    results = map(model, ~broom::tidy(., conf.int = TRUE, exponentiate = TRUE))
  ) |> 
  unnest(results) |> 
  # Filter for the term of interest (victim_sexMale)
  filter(term == "victim_sexMale") |> 
  select(city_state, estimate, conf.low, conf.high)

```

# Viz
We create a plot showing the estimated Odds Ratios and Confidence Intervals for each city, ordered by the magnitude of the OR.

```{r}
city_results |> 
  ungroup() |>   # <--- THIS IS THE MISSING STEP
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  coord_flip() +
  labs(
    title = "Odds Ratio for Solving Homicides: Male vs Female Victims",
    subtitle = "Adjusted for victim age and race",
    x = "City",
    y = "Adjusted Odds Ratio (Male / Female)"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 6))
```

The plot displays the estimated adjusted odds ratios (ORs) for solving homicides comparing male victims to female victims across various major U.S. cities.

In the vast majority of cities, the estimated odds ratio is below 1. This suggests that, holding victim age and race constant, homicides involving male victims are less likely to be cleared (solved) than those involving female victims.

Cities at the bottom of the plot (e.g., New York, NY; Long Beach, CA) show the strongest disparity, with ORs significantly below 0.5. This implies a very strong negative association between male victimhood and case resolution in these locations.

Only a handful of cities (e.g., Fresno, CA; Minneapolis, MN; Stockton, CA) have estimated ORs greater than 1. However, looking at the confidence intervals (the error bars), most of these intervals cross the vertical line at OR = 1, meaning the difference is not statistically significant in those cases.

Overall, there is a clear systematic trend across the U.S. where cases with female victims tend to have higher resolution rates compared to cases with male victims.

## Problem 2
```{r}
library(p8105.datasets)
library(modelr)
data("weather_df")

set.seed(1)

```


```{r}

weather_central_park = 
  weather_df |>  
  filter(name == "CentralPark_NY") |>  
  select(tmax, tmin, prcp) |>  
  drop_na()

```

# Bootstrapping
```{r}
# Generate 5000 bootstrap samples
boot_straps = 
  weather_central_park |>  
  modelr::bootstrap(n = 5000)

# Fit models and extract results
bootstrap_results = 
  boot_straps |>  
  mutate(
    # Fit the linear model to each bootstrap sample
    models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    
    # Extract R-squared using broom::glance
    glance_results = map(models, broom::glance),
    
    # Extract coefficients using broom::tidy
    tidy_results = map(models, broom::tidy)
  ) 

# Clean up the results for analysis
final_results = 
  bootstrap_results |>  
  select(.id, glance_results, tidy_results) |>  
  unnest(glance_results) |>  
  select(.id, r.squared, tidy_results) |>  
  unnest(tidy_results) |>  
  select(.id, r.squared, term, estimate) |>  
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) |>  
  mutate(
    beta_ratio = tmin / prcp # Calculating beta1 / beta2
  ) |>  
  select(.id, r.squared, beta_ratio)

```

# Dist for r squared
```{r}
final_results |>  
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(
    title = "Distribution of Estimated R-squared",
    x = "Estimated R-squared",
    y = "Density"
  ) +
  theme_minimal()

```

The distribution of \(\hat{r}^2\) appears to be approximately normal, though it may exhibit a slight left skew (tail extending towards lower values). The values are generally high, indicating that tmin and prcp are strong predictors of tmax.


# Dist for beta1/beta2
```{r}
final_results |>  
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(
    title = "Distribution of Estimated Beta Ratio (tmin / prcp) (Zoomed in)",
    x = "Estimate Beta1 / Beta2",
    y = "Density"
  ) +
  coord_cartesian(xlim = c(-50000, 50000)) + 
  theme_minimal() 
```

The distribution is unimodal and roughly symmetric, centered around approximately -25. This indicates that for the majority of bootstrap samples, the coefficient for minimum temperature ($\hat{\beta}_1$) is positive and the coefficient for precipitation ($\hat{\beta}_2$) is small and negative. 

```{r}
final_results |>  
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(
    title = "Distribution of Estimated Beta Ratio (tmin / prcp)",
    x = "Estimate Beta1 / Beta2",
    y = "Density"
  ) +
  theme_minimal() 
```
Here's the distribution without zooming in. The heavy tails are due to bootstrap samples where the precipitation coefficient is extremely close to zero, causing the ratio to take on extreme values.

# Confidence Interval
```{r}
ci_results = 
  final_results |>  
  summarize(
    r_squared_lower = quantile(r.squared, 0.025),
    r_squared_upper = quantile(r.squared, 0.975),
    beta_ratio_lower = quantile(beta_ratio, 0.025, na.rm = TRUE),
    beta_ratio_upper = quantile(beta_ratio, 0.975, na.rm = TRUE)
  )

knitr::kable(ci_results, digits = 3, caption = "95% Confidence Intervals")

```



## Problem 3

```{r}
library(modelr)
library(purrr)
```


```{r}
birthweight_data <- read_csv("data/birthweight.csv")

# Clean data: convert appropriate integers to factors
birthweight_clean <- birthweight_data |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  )

# Check for missing data
sum(is.na(birthweight_clean))
```

# Proposed model: Maternal and Pregnancy factors

A model is proposed based on developmental and maternal factors. Key predictors include gestational age (gaweeks), mother's physical characteristics (ppbmi, mheight), and health behaviors (smoken).

```{r}
model_proposed <- lm(bwt ~ gaweeks + smoken + mheight + ppbmi + wtgain + parity, data = birthweight_clean)

# Add predictions and residuals
birthweight_clean <- birthweight_clean |> 
  add_predictions(model_proposed, var = "pred_proposed") |> 
  add_residuals(model_proposed, var = "resid_proposed")

# Plot residuals vs fitted values
ggplot(birthweight_clean, aes(pred_proposed, resid_proposed)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values (Proposed Model)",
    x = "Fitted Birthweight (grams)",
    y = "Residuals"
  ) +
  theme_minimal()
```

The plot of residuals against fitted values for this proposed model shows a random scatter around zero, suggesting that the linear assumption is largely appropriate, although there is some variance.

# Model comparison via Cross-Validation
```{r}

set.seed(123)

# Create cross-validation folds (Monte Carlo, 100 splits)
cv_df <- crossv_mc(birthweight_clean, n = 100)

# Define the models and compute RMSE
cv_results <- cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    
    # Fit models
    mod_proposed = map(train, ~lm(bwt ~ gaweeks + smoken + mheight + ppbmi + wtgain + parity, data = .)),
    mod_main     = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
    mod_interact = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .)),
    
    # Calculate RMSE on test sets
    rmse_proposed = map2_dbl(mod_proposed, test, rmse),
    rmse_main     = map2_dbl(mod_main, test, rmse),
    rmse_interact = map2_dbl(mod_interact, test, rmse)
  )

# Reshape for plotting
cv_long <- cv_results |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  )

# Visualize RMSE comparison
ggplot(cv_long, aes(x = reorder(model, rmse), y = rmse, fill = model)) +
  geom_boxplot() +
  labs(
    title = "Model Comparison: Cross-Validated Prediction Error",
    x = "Model",
    y = "RMSE (grams)"
  ) +
  theme_minimal()

# Summary Statistics
cv_long |> 
  group_by(model) |> 
  summarize(mean_rmse = mean(rmse)) |> 
  knitr::kable()
```

Using Monte Carlo cross-validation (100 splits, 80/20 train/test), the Root Mean Square Error (RMSE) was calculated for three models to assess prediction accuracy.



  * Model 1 (Including the three-way interaction: Head Circ. $\times$ Length $\times$ Sex Interactions): RMSE $\approx$ 291 grams
  * Model 2 (Main effects only: Length + Gestational Age): RMSE $\approx$ 335 grams
  * Proposed Model (Maternal Factors): RMSE $\approx$ 442 grams
 
Conclusion: Model 1 significantly outperforms the others. This is expected as head circumference and body length are direct physical dimensions of the baby at birth and are mathematically correlated with volume and mass (weight). The proposed model relies on maternal characteristics, which explain less variance than direct measurements of the infant.

